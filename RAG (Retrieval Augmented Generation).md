It's a technique that enhances LLM generation by retrieving the relevant information from external memory sources.
## Architecture
It has two components, the most important being the retriever, the success of  a RAG depends on it's quality.

#Retriever: retrieves information from an external source. It has two main functions **indexing** and **querying**.
* Indexing: processing the data so it can be quickly retrieved later.
* Querying: sending a query to retrieve relevant data.

#Generator : generates a response based on the retrieved information.

## Retrieval Algorithms
The most common retrieval mechanisms are: term-based retrieval and embedding-based retrieval. 

>[!INFO] Sparse vs Dense retrieval
>Retrieval algorithms can also be divided in Sparse vs Dense.
>
>- **Sparse retrievers** represent data using sparse vectors, a vector where the mayority of its values is 0. **Term-based Retrieval** is considered sparse as each term can be represented using a sparse *one-hot vector*. The vector size is the length of the vocabulary. This is specially useful when we have simple dictionaries.
>
>- **Dense retrivers** use *dense vectors*, where the mayority od the values aren't 0. Embedding-based retrieval is tipically considered dense. However there are some sparse embeddings. SPLADE(Sparse Lexical and Expansion) is a retrieval algorithm that uses sparse embeddings. It leverages embedding generated by BERT, but uses regularization to push most embedding values to 0. Sparsity makes embedding operations more efficient.

#### Term-based retrieval
If we use keywords to find relevant documents, a pretty straight forward approach, we encounter 2 problems:

* Many documents might contain the given term, making it so the model wont have enough context to fit all. The assumption is that the more a term appears in a document, the more relevant this document is to the term. This is called  **Term frequency (TF)**.
* A prompt can be long and contain many terms. We need a way to identify important terms. An intuition is that the more documents contain a term, the less informative this term is. This is called **Inverse Document Frequency (IDF)**

**TF-IDF** is an algorithm that combines this two metrics,

Two common term-based retrieval solutions are **ElasticSearch** and **BM25**.
	- **ElasticSearch**: uses a data structure called an inverted index. It's a dictionary that maps from terms to documents that contain them.
	- **BM25**: normalizes term frequency scores by document length. Longer documents are most likely to contain a given term and have a  higher term frequency values.
